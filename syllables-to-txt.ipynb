{"cells":[{"cell_type":"markdown","metadata":{"id":"X4cRE8IbIrIV"},"source":["If you're opening this Notebook on colab, you will probably need to install ğŸ¤— Transformers and ğŸ¤— Datasets as well as other dependencies. Uncomment the following cell and run it."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T10:09:37.658946Z","iopub.status.busy":"2023-07-28T10:09:37.658357Z","iopub.status.idle":"2023-07-28T10:09:51.945029Z","shell.execute_reply":"2023-07-28T10:09:51.943832Z","shell.execute_reply.started":"2023-07-28T10:09:37.658911Z"},"id":"MOsHUjgdIrIW","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.65.0)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.6.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"]}],"source":["!pip install datasets transformers "]},{"cell_type":"markdown","metadata":{"id":"whPRbBNbIrIl"},"source":["## Loading the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd \n","df=pd.read_csv(\"/kaggle/working/our_data.csv\")\n","df1=df[0:20000]\n","df1.to_csv(\"ourr_data.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["ef1e01985867419f9bb6a46bc1f93ffe"]},"execution":{"iopub.execute_input":"2023-07-28T10:09:51.949153Z","iopub.status.busy":"2023-07-28T10:09:51.948836Z","iopub.status.idle":"2023-07-28T10:09:54.281451Z","shell.execute_reply":"2023-07-28T10:09:54.280500Z","shell.execute_reply.started":"2023-07-28T10:09:51.949123Z"},"id":"IreSlFmlIrIm","outputId":"3a61bd46-e656-432f-9ef4-507a700fbefe","trusted":true},"outputs":[],"source":["from datasets import load_dataset\n","\n","raw_datasets = load_dataset(\"csv\", data_files=\"/kaggle/working/our_data2.csv\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T10:09:54.283695Z","iopub.status.busy":"2023-07-28T10:09:54.283035Z","iopub.status.idle":"2023-07-28T10:09:54.290615Z","shell.execute_reply":"2023-07-28T10:09:54.289528Z","shell.execute_reply.started":"2023-07-28T10:09:54.283661Z"},"trusted":true},"outputs":[],"source":["raw_datasets=raw_datasets.remove_columns(['Unnamed: 0.1','Unnamed: 0'])"]},{"cell_type":"markdown","metadata":{"id":"RzfPtOMoIrIu"},"source":["The `dataset` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set:"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T10:09:54.294797Z","iopub.status.busy":"2023-07-28T10:09:54.294088Z","iopub.status.idle":"2023-07-28T10:09:54.328135Z","shell.execute_reply":"2023-07-28T10:09:54.327301Z","shell.execute_reply.started":"2023-07-28T10:09:54.294764Z"},"id":"GWiVUF0jIrIv","outputId":"35e3ea43-f397-4a54-c90c-f2cf8d36873e","trusted":true},"outputs":[],"source":["raw_datasets = raw_datasets[\"train\"].train_test_split(test_size=.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X6HrpprwIrIz","outputId":"d7670bc0-42e4-4c09-8a6a-5c018ded7d95","trusted":true},"outputs":[],"source":["raw_datasets"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T10:09:54.329840Z","iopub.status.busy":"2023-07-28T10:09:54.329511Z","iopub.status.idle":"2023-07-28T10:09:54.337169Z","shell.execute_reply":"2023-07-28T10:09:54.336308Z","shell.execute_reply.started":"2023-07-28T10:09:54.329809Z"},"trusted":true},"outputs":[],"source":["import re\n","chars_to_ignore_regex = '[\\,\\?\\!\\-\\;\\:\\\\\\%\\\\ï¿½\\+\\ØŸ\\[\\]\\ØŒ\\\\*\\\\&\\\\ufeff\\\\Ù€\\'Ù‘\\$]'\n","\n","\n","def remove_special_characters(batch):\n","    batch[\"txt\"] = re.sub(chars_to_ignore_regex, '', batch[\"txt\"]).lower()\n","    batch[\"txt\"] = re.sub('[a-z]','',batch[\"txt\"])  \n","    batch[\"syllables\"] = re.sub(chars_to_ignore_regex, '', batch[\"syllables\"]).lower()\n","    batch[\"syllables\"] = re.sub('[a-z]','',batch[\"syllables\"])   \n","    return batch"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T10:09:54.339331Z","iopub.status.busy":"2023-07-28T10:09:54.338431Z","iopub.status.idle":"2023-07-28T10:10:00.615786Z","shell.execute_reply":"2023-07-28T10:10:00.614844Z","shell.execute_reply.started":"2023-07-28T10:09:54.339296Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c3bff05ba4d4e95a3b832d7cddfac2d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/47269 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"915c8e22e9b94dfeb7603c2083a356a5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5253 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"}],"source":["raw_datasets['train']=raw_datasets['train'].map(remove_special_characters)\n","raw_datasets['test']=raw_datasets['test'].map(remove_special_characters)\n","\n","#valid=valid.map(remove_special_characters)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["raw_datasets"]},{"cell_type":"markdown","metadata":{"id":"WHUmphG3IrI3"},"source":["To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset."]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T10:10:00.617308Z","iopub.status.busy":"2023-07-28T10:10:00.616931Z","iopub.status.idle":"2023-07-28T10:10:00.625612Z","shell.execute_reply":"2023-07-28T10:10:00.624686Z","shell.execute_reply.started":"2023-07-28T10:10:00.617273Z"},"id":"i3j8APAoIrI3","trusted":true},"outputs":[],"source":["import datasets\n","import random\n","import pandas as pd\n","from IPython.display import display, HTML\n","\n","def show_random_elements(dataset, num_examples=5):\n","    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n","    picks = []\n","    for _ in range(num_examples):\n","        pick = random.randint(0, len(dataset)-1)\n","        while pick in picks:\n","            pick = random.randint(0, len(dataset)-1)\n","        picks.append(pick)\n","\n","    df = pd.DataFrame(dataset[picks])\n","    for column, typ in dataset.features.items():\n","        if isinstance(typ, datasets.ClassLabel):\n","            df[column] = df[column].transform(lambda i: typ.names[i])\n","    display(HTML(df.to_html()))"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T10:10:00.627035Z","iopub.status.busy":"2023-07-28T10:10:00.626659Z","iopub.status.idle":"2023-07-28T10:10:00.658118Z","shell.execute_reply":"2023-07-28T10:10:00.657018Z","shell.execute_reply.started":"2023-07-28T10:10:00.627000Z"},"id":"SZy5tRB_IrI7","outputId":"ba8f2124-e485-488f-8c0c-254f34f24f13","trusted":true},"outputs":[{"data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>syllables</th>\n","      <th>txt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>|ÙˆÙ|Ù†Ù|ÙÙØ§Ù’|Ø¯Ù|Ù‚ÙÙˆÙ’|ÙˆÙ|ØªÙÙ„Ù’|Ù…ÙØ±Ù’|Ø¡Ù|ØªÙ|Ø¨ÙÙ„Ù’|Ø­ÙÙ…Ù’|Ù„Ù|ÙˆÙ|Ù„ÙØªÙ’|ØªÙØ±Ù’|Ø¨Ù|ÙŠÙÙ‡Ù’.</td>\n","      <td>ÙˆÙÙ†ÙÙÙØ§Ø¯Ù|Ù‚ÙÙˆÙØ©Ù|Ø§Ù„Ù’Ù…ÙØ±Ù’Ø£ÙØ©Ù|Ø¨ÙØ§Ù„Ù’Ø­ÙÙ…Ù’Ù„Ù|ÙˆÙØ§Ù„ØªÙØ±Ù’Ø¨ÙÙŠÙØ©Ù.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>|Ø¡Ù|Ø®Ù|Ø°ÙØ·Ù’|Ø·ÙØ§Ù’|Ù„Ù|Ø¨Ù|ÙƒÙ|ØªÙ|Ø¨ÙÙ‡Ù’.</td>\n","      <td>Ø£ÙØ®ÙØ°Ù|Ø§Ù„Ø·ÙØ§Ù„ÙØ¨Ù|ÙƒÙØªÙØ¨ÙÙ‡Ù.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>|ÙÙÙ„Ù’|ÙˆÙÙ‚Ù’|ØªÙÙ„Ù’|Ù„Ù|Ø°ÙÙŠÙ’|ÙƒÙØ§Ù’|Ù†Ù|ÙÙÙŠÙ’|Ú¾Ù|Ù…ÙØ¹Ù’|Ø¸Ù|Ù…ÙÙ„Ù’|Ù…Ù|Ø´ÙØ§Ù’|Ø±Ù|ÙƒÙÙŠÙ’|Ù†Ù|ÙÙÙŠÙ’|Ø­ÙÙ…Ù’|Ù„Ù|ØªÙÙ†Ù’|Ù†Ù|Ø¸ÙØ§Ù’|ÙÙ|ØªÙ|ÙŠÙØ­Ù’|ØªÙ|ÙÙ|Ø¸ÙÙˆÙ’|Ù†Ù|ÙÙÙŠÙ’|Ø¡ÙÙŠÙ’|Ø¯ÙÙŠÙ’|Ú¾ÙÙ…Ù’|Ø¨Ù|Ø¹ÙÙ„Ù’|Ø¨Ù|Ú¾ÙÙ†Ù’.</td>\n","      <td>ÙÙÙŠ|Ø§Ù„Ù’ÙˆÙÙ‚Ù’ØªÙ|Ø§Ù„ÙØ°ÙÙŠ|ÙƒÙØ§Ù†Ù|ÙÙÙŠÙ‡Ù|Ù…ÙØ¹Ù’Ø¸ÙÙ…Ù|Ø§Ù„Ù’Ù…ÙØ´ÙØ§Ø±ÙÙƒÙÙŠÙ†Ù|ÙÙÙŠ|Ø­ÙÙ…Ù’Ù„ÙØ©Ù|Ø§Ù„Ù†ÙØ¸ÙØ§ÙÙØ©Ù|ÙŠÙØ­Ù’ØªÙÙÙØ¸ÙÙˆÙ†Ù|ÙÙÙŠ|Ø£ÙÙŠÙ’Ø¯ÙÙŠÙ‡ÙÙ…Ù’|Ø¨ÙØ¹ÙÙ„Ù’Ø¨ÙØ©Ù.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>|ÙƒÙÙ„Ù’|Ù„Ù|Ù…Ù|ÙˆÙØ§Ù’|Ø·Ù|Ù†ÙÙ…Ù’|Ù…Ù|Ù†ÙÙ„Ù’|Ø­Ù|ØµÙÙˆÙ’|Ù„Ù|Ø¹Ù|Ù„ÙÙ‰|Ø­ÙÙ‚Ù’|Ù‚Ù|Ú¾ÙÙ„Ù’|Ù…ÙØ´Ù’|Ø±ÙÙˆÙ’|Ø¹Ù|ÙÙ|ÙŠÙØµÙ’|ØµÙØ­Ù’|Ø­Ù|ØªÙ|ÙˆÙÙ„Ù’|Ø­Ù|ÙŠÙØ§Ù’Ù‡Ù’.</td>\n","      <td>ÙƒÙÙ„Ù|Ù…ÙÙˆÙØ§Ø·ÙÙ†Ù|Ù…ÙÙ†Ù’|Ø§Ù„Ù’Ø­ÙØµÙÙˆÙ„Ù|Ø¹ÙÙ„ÙÙ‰|Ø­ÙÙ‚ÙÙ‡Ù|Ø§Ù„Ù’Ù…ÙØ´Ù’Ø±ÙÙˆØ¹Ù|ÙÙÙŠ|Ø§Ù„ØµÙØ­ÙØ©Ù|ÙˆÙØ§Ù„Ù’Ø­ÙÙŠÙØ§Ø©Ù.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>|ÙÙÙ„Ù’|ÙˆÙÙ‚Ù’|ØªÙ|Ù†ÙÙÙ’|Ø³Ù|Ú¾Ù|Ù…Ù|Ø¹Ù|Ø·Ù|Ù„ÙØ§Ù’|Ø¡Ù|Ø¹ÙÙ†Ù’|Ù†Ù|ÙˆÙÙ‰|ÙÙ|ÙÙÙƒÙ’|ÙƒÙ|Ø±ÙÙˆÙ’|ÙÙÙŠÙ’|Ø¡ÙÙ…Ù’|ÙƒÙØ§Ù’|Ù†ÙÙŠÙ’|ÙŠÙ|ØªÙ|Ø¡ÙÙŠÙ’|ÙŠÙØ³Ù’|ØªÙØ®Ù’|Ø¯Ù|Ù…Ù|ÙˆÙØªÙ’|ØªÙ|Ù‚Ù|Ù†ÙÙŠÙ’|ÙŠÙ|ØªÙ|Ù„Ù|Ù†ÙÙ‚Ù’Ù„Ù’.</td>\n","      <td>ÙÙÙŠ|Ø§Ù„Ù’ÙˆÙÙ‚Ù’ØªÙ|Ù†ÙÙÙ’Ø³ÙÙ‡Ù|Ù…ÙØ¹Ù|Ø·ÙÙ„ÙØ§Ø¦ÙØ¹Ù|Ø§Ù„Ù†ÙÙˆÙÙ‰|ÙÙÙÙÙƒÙØ±ÙÙˆØ§|ÙÙÙŠ|Ø¥ÙÙ…Ù’ÙƒÙØ§Ù†ÙÙŠÙØ©Ù|Ø£ÙÙ†Ù’|ÙŠÙØ³Ù’ØªÙØ®Ù’Ø¯ÙÙ…ÙÙˆØ§|Ø§Ù„ØªÙÙ‚ÙÙ†ÙÙŠÙØ©Ù|Ù„ÙÙ†ÙÙ‚Ù’Ù„Ù.</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["show_random_elements(raw_datasets['train'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["raw_datasets"]},{"cell_type":"markdown","metadata":{"id":"lnjDIuQ3IrI-"},"source":["The metric is an instance of [`datasets.Metric`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Metric):"]},{"cell_type":"markdown","metadata":{"id":"jAWdqcUBIrJC"},"source":["You can call its `compute` method with your predictions and labels, which need to be list of decoded strings:"]},{"cell_type":"markdown","metadata":{"id":"n9qywopnIrJH"},"source":["## Preprocessing the data"]},{"cell_type":"markdown","metadata":{"id":"YVx71GdAIrJH"},"source":["Before we can feed those texts to our model, we need to preprocess them. This is done by a ğŸ¤— Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that the model requires.\n","\n","To do all of this, we instantiate our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n","\n","- we get a tokenizer that corresponds to the model architecture we want to use,\n","- we download the vocabulary used when pretraining this specific checkpoint.\n","\n","That vocabulary will be cached, so it's not downloaded again the next time we run the cell."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T10:10:00.669908Z","iopub.status.busy":"2023-07-28T10:10:00.669632Z","iopub.status.idle":"2023-07-28T10:14:42.721306Z","shell.execute_reply":"2023-07-28T10:14:42.720310Z","shell.execute_reply.started":"2023-07-28T10:10:00.669871Z"},"id":"eXNLu_-nIrJI","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e0976f66e03647c1bb64f021e48cbd9d","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/702 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a01b467fb8ce433a911945e716c90df7","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c307800f85141b9aa04a839149f7bd7","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b7464fdedfba40cdb6eb9744b6621f26","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/402 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d64e045760354d14b755591a22770ec8","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)olve/main/vocab.json:   0%|          | 0.00/537 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac5d64cb7a83466fa6851fb5a843db83","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)in/added_tokens.json:   0%|          | 0.00/30.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc0e70538ba04337a7dc57703040fe78","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/679 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoTokenizer\n","from transformers import MT5ForConditionalGeneration, AutoTokenizer\n","\n","model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-base\")\n","\n","# this tokenizer contains al arabic chars\n","tokenizer1 = AutoTokenizer.from_pretrained('IbrahimSalah/wav_chars_.155')\n","\n","tokenizer=tokenizer1"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T10:14:42.723475Z","iopub.status.busy":"2023-07-28T10:14:42.722771Z","iopub.status.idle":"2023-07-28T10:14:42.730928Z","shell.execute_reply":"2023-07-28T10:14:42.729541Z","shell.execute_reply.started":"2023-07-28T10:14:42.723438Z"},"id":"vc0BSBLIIrJQ","trusted":true},"outputs":[],"source":["max_input_length = 8129\n","max_target_length = 8129\n","\n","def preprocess_function(examples):\n","    model_inputs = tokenizer(examples[\"syllables\"], max_length=max_input_length, truncation=True)\n","\n","    # Setup the tokenizer for targets\n","    labels = tokenizer(text_target=examples[\"txt\"], max_length=max_target_length, truncation=True)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"]},{"cell_type":"markdown","metadata":{"id":"zS-6iXTkIrJT"},"source":["To apply this function on all the pairs of sentences in our dataset, we just use the `map` method of our `dataset` object we created earlier. This will apply the function on all the elements of all the splits in `dataset`, so our training, validation and testing data will be preprocessed in one single command."]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T10:14:42.733119Z","iopub.status.busy":"2023-07-28T10:14:42.732397Z","iopub.status.idle":"2023-07-28T10:15:07.670318Z","shell.execute_reply":"2023-07-28T10:15:07.669261Z","shell.execute_reply.started":"2023-07-28T10:14:42.733085Z"},"id":"DDtsaJeVIrJT","outputId":"aa4734bf-4ef5-4437-9948-2c16363da719","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"670376a8413f41dba1d3253e90c0bb0b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/48 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ff07b84d4534a37a5c6dcf7d82d49ab","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_datasets = raw_datasets['train'].map(preprocess_function, batched=True)\n","tokenized_datasets2 =raw_datasets['test'].map(preprocess_function, batched=True)\n","\n","#valid = valid.map(preprocess_function, batched=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T10:15:07.674177Z","iopub.status.busy":"2023-07-28T10:15:07.673877Z","iopub.status.idle":"2023-07-28T10:15:07.813697Z","shell.execute_reply":"2023-07-28T10:15:07.812544Z","shell.execute_reply.started":"2023-07-28T10:15:07.674150Z"},"id":"PKzeFdEsDQGx","trusted":true},"outputs":[],"source":["from transformers import TrainingArguments,Seq2SeqTrainingArguments\n","\n","batch_size = 16\n","#model_name = model_checkpoint.split(\"/\")[-1]\n","args = Seq2SeqTrainingArguments(\n","    \"model\",\n","    evaluation_strategy = \"steps\",\n","    learning_rate=1e-5,\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=4,\n","    weight_decay=0.01,\n","    eval_steps=500,\n","    save_steps=1000,\n","    save_total_limit=1,\n","    num_train_epochs=20,\n","    logging_steps=100,\n","    fp16=False\n","   \n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T10:15:07.816069Z","iopub.status.busy":"2023-07-28T10:15:07.815396Z","iopub.status.idle":"2023-07-28T10:15:08.582347Z","shell.execute_reply":"2023-07-28T10:15:08.581325Z","shell.execute_reply.started":"2023-07-28T10:15:07.816035Z"},"id":"5kOqknfJDQGx","trusted":true},"outputs":[],"source":["from transformers import DataCollatorForSeq2Seq\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"]},{"cell_type":"markdown","metadata":{"id":"rXuFTAzDIrJe"},"source":["Then we just need to pass all of this along with our datasets to the `Seq2SeqTrainer`:"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T10:15:08.589448Z","iopub.status.busy":"2023-07-28T10:15:08.587153Z","iopub.status.idle":"2023-07-28T10:15:13.343695Z","shell.execute_reply":"2023-07-28T10:15:13.342666Z","shell.execute_reply.started":"2023-07-28T10:15:08.589408Z"},"id":"imY1oC3SIrJf","trusted":true},"outputs":[],"source":["from transformers import Seq2SeqTrainer\n","trainer = Seq2SeqTrainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_datasets,\n","    eval_dataset=tokenized_datasets2,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","  \n",")"]},{"cell_type":"markdown","metadata":{"id":"CdzABDVcIrJg"},"source":["We can now finetune our model by just calling the `train` method:"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T10:15:13.345812Z","iopub.status.busy":"2023-07-28T10:15:13.344977Z","iopub.status.idle":"2023-07-28T10:15:13.351749Z","shell.execute_reply":"2023-07-28T10:15:13.350687Z","shell.execute_reply.started":"2023-07-28T10:15:13.345776Z"},"trusted":true},"outputs":[],"source":["import os \n","os.environ ['WANDB_MODE'] = 'offline'\n","os.environ[\"WANDB_DISABLED\"] = \"true\""]},{"cell_type":"markdown","metadata":{},"source":["* I stopped the trainning process since I reached the desired loss "]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T10:15:13.354141Z","iopub.status.busy":"2023-07-28T10:15:13.353403Z","iopub.status.idle":"2023-07-28T11:21:23.044671Z","shell.execute_reply":"2023-07-28T11:21:23.036086Z","shell.execute_reply.started":"2023-07-28T10:15:13.354104Z"},"id":"uNx5pyRlIrJh","outputId":"077e661e-d36c-469b-89b8-7ff7f73541ec","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.5"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='21234' max='236360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 21234/236360 1:04:56 < 32:11:32, 1.86 it/s, Epoch 1.80/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>14500</td>\n","      <td>0.081100</td>\n","      <td>0.063459</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>0.068100</td>\n","      <td>0.058899</td>\n","    </tr>\n","    <tr>\n","      <td>15500</td>\n","      <td>0.068500</td>\n","      <td>0.055880</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>0.070200</td>\n","      <td>0.053484</td>\n","    </tr>\n","    <tr>\n","      <td>16500</td>\n","      <td>0.065300</td>\n","      <td>0.050569</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>0.058300</td>\n","      <td>0.049411</td>\n","    </tr>\n","    <tr>\n","      <td>17500</td>\n","      <td>0.059800</td>\n","      <td>0.048941</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>0.062700</td>\n","      <td>0.048167</td>\n","    </tr>\n","    <tr>\n","      <td>18500</td>\n","      <td>0.057300</td>\n","      <td>0.048274</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>0.057700</td>\n","      <td>0.047828</td>\n","    </tr>\n","    <tr>\n","      <td>19500</td>\n","      <td>0.061800</td>\n","      <td>0.048003</td>\n","    </tr>\n","    <tr>\n","      <td>20000</td>\n","      <td>0.062200</td>\n","      <td>0.047597</td>\n","    </tr>\n","    <tr>\n","      <td>20500</td>\n","      <td>0.073300</td>\n","      <td>0.047197</td>\n","    </tr>\n","    <tr>\n","      <td>21000</td>\n","      <td>0.056700</td>\n","      <td>0.047450</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>1 trainer.train(resume_from_checkpoint =<span style=\"color: #808000; text-decoration-color: #808000\">'/kaggle/working/model/checkpoint-14000'</span>)              <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1645</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1643 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1644 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>1645 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1646 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1647 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1648 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2007</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>     <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2004 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   </span>scale_after = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler.get_scale()                             <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2005 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   </span>optimizer_was_run = scale_before &lt;= scale_after                   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2006 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>2007 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer.step()                                             <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2008 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   </span>optimizer_was_run = <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.optimizer_step_was_skip  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2009 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   â”‚   </span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2010 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> optimizer_was_run:                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">optimizer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">140</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">step</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># If we reduced the loss scale, it means the optimizer step was skipped </span>   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._is_overflow = scale_after &lt; scale_before                             <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>140 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer.step(closure)                                               <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_switch_parameters</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, parameters_map):                                          <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> param_group <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer.param_groups:                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">lr_scheduler.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">69</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  66 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span>instance = instance_ref()                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  67 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span>instance._step_count += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  68 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span>wrapped = func.<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__get__</span>(instance, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>)                                     <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>  69 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapped(*args, **kwargs)                                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  70 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  71 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Note that the returned function here is no longer a bound method,</span>           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  72 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># so attributes like `__func__` and `__self__` no longer exist.</span>               <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">optimizer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">280</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">277 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span>func<span style=\"color: #808000; text-decoration-color: #808000\">} must return None or a tuple of (</span>   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">278 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"but got {</span>result<span style=\"color: #808000; text-decoration-color: #808000\">}.\"</span>)                       <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">279 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>280 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span>out = func(*args, **kwargs)                                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">281 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._optimizer_step_code()                                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">282 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">283 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># call optimizer step post hooks</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_contextlib.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">115</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>       <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>(*args, **kwargs):                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> ctx_factory():                                                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>115 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> decorate_context                                                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">optimization.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">468</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">step</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">465 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># In-place operations to update the averages at the same time</span>              <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">466 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span>exp_avg.mul_(beta1).add_(grad, alpha=(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1.0</span> - beta1))                        <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">467 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span>exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1.0</span> - beta2)             <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>468 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span>denom = exp_avg_sq.sqrt().add_(group[<span style=\"color: #808000; text-decoration-color: #808000\">\"eps\"</span>])                               <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">469 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">470 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span>step_size = group[<span style=\"color: #808000; text-decoration-color: #808000\">\"lr\"</span>]                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">471 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> group[<span style=\"color: #808000; text-decoration-color: #808000\">\"correct_bias\"</span>]:  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># No bias correction for Bert</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n","</pre>\n"],"text/plain":["\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\n","\u001b[31mâ”‚\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m1 trainer.train(resume_from_checkpoint =\u001b[33m'\u001b[0m\u001b[33m/kaggle/working/model/checkpoint-14000\u001b[0m\u001b[33m'\u001b[0m)              \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1645\u001b[0m in \u001b[92mtrain\u001b[0m                    \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m1642 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m1643 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m1644 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m)                                                                                 \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m1645 \u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m1646 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0margs=args,                                                                    \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m1647 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m1648 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0mtrial=trial,                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2007\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m     \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m2004 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0mscale_after = \u001b[96mself\u001b[0m.scaler.get_scale()                             \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m2005 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0moptimizer_was_run = scale_before <= scale_after                   \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m2006 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[94melse\u001b[0m:                                                                 \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m2007 \u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[96mself\u001b[0m.optimizer.step()                                             \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m2008 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0moptimizer_was_run = \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m.accelerator.optimizer_step_was_skip  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m2009 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m                                                                      \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m2010 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m optimizer_was_run:                                                 \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/accelerate/\u001b[0m\u001b[1;33moptimizer.py\u001b[0m:\u001b[94m140\u001b[0m in \u001b[92mstep\u001b[0m                      \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[2m# If we reduced the loss scale, it means the optimizer step was skipped \u001b[0m   \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[96mself\u001b[0m._is_overflow = scale_after < scale_before                             \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m140 \u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[96mself\u001b[0m.optimizer.step(closure)                                               \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                                       \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_switch_parameters\u001b[0m(\u001b[96mself\u001b[0m, parameters_map):                                          \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m143 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mfor\u001b[0m param_group \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.optimizer.param_groups:                                    \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/optim/\u001b[0m\u001b[1;33mlr_scheduler.py\u001b[0m:\u001b[94m69\u001b[0m in \u001b[92mwrapper\u001b[0m                \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m  66 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0minstance = instance_ref()                                                 \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m  67 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0minstance._step_count += \u001b[94m1\u001b[0m                                                 \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m  68 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mwrapped = func.\u001b[92m__get__\u001b[0m(instance, \u001b[96mcls\u001b[0m)                                     \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m  69 \u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[94mreturn\u001b[0m wrapped(*args, **kwargs)                                           \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m  70 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m  71 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[2m# Note that the returned function here is no longer a bound method,\u001b[0m           \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m  72 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[2m# so attributes like `__func__` and `__self__` no longer exist.\u001b[0m               \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/optim/\u001b[0m\u001b[1;33moptimizer.py\u001b[0m:\u001b[94m280\u001b[0m in \u001b[92mwrapper\u001b[0m                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m277 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0mfunc\u001b[33m}\u001b[0m\u001b[33m must return None or a tuple of (\u001b[0m   \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m278 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mbut got \u001b[0m\u001b[33m{\u001b[0mresult\u001b[33m}\u001b[0m\u001b[33m.\u001b[0m\u001b[33m\"\u001b[0m)                       \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m279 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m                                                                           \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m280 \u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mout = func(*args, **kwargs)                                                \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m281 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[96mself\u001b[0m._optimizer_step_code()                                                \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m282 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m                                                                           \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m283 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[2m# call optimizer step post hooks\u001b[0m                                           \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/utils/\u001b[0m\u001b[1;33m_contextlib.py\u001b[0m:\u001b[94m115\u001b[0m in \u001b[92mdecorate_context\u001b[0m       \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                                                 \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                                                 \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mwith\u001b[0m ctx_factory():                                                                \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m115 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                                       \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mreturn\u001b[0m decorate_context                                                                \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m118 \u001b[0m                                                                                           \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33moptimization.py\u001b[0m:\u001b[94m468\u001b[0m in \u001b[92mstep\u001b[0m                 \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m465 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[2m# In-place operations to update the averages at the same time\u001b[0m              \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m466 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mexp_avg.mul_(beta1).add_(grad, alpha=(\u001b[94m1.0\u001b[0m - beta1))                        \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m467 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mexp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=\u001b[94m1.0\u001b[0m - beta2)             \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m468 \u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mdenom = exp_avg_sq.sqrt().add_(group[\u001b[33m\"\u001b[0m\u001b[33meps\u001b[0m\u001b[33m\"\u001b[0m])                               \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m469 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m                                                                           \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m470 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mstep_size = group[\u001b[33m\"\u001b[0m\u001b[33mlr\u001b[0m\u001b[33m\"\u001b[0m]                                                    \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m471 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m group[\u001b[33m\"\u001b[0m\u001b[33mcorrect_bias\u001b[0m\u001b[33m\"\u001b[0m]:  \u001b[2m# No bias correction for Bert\u001b[0m                   \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n","\u001b[1;91mKeyboardInterrupt\u001b[0m\n"]},"metadata":{},"output_type":"display_data"}],"source":["trainer.train(resume_from_checkpoint ='/kaggle/working/model/checkpoint-14000')"]},{"cell_type":"markdown","metadata":{},"source":["# check the output model with example "]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T11:22:51.701460Z","iopub.status.busy":"2023-07-28T11:22:51.701072Z","iopub.status.idle":"2023-07-28T11:23:03.988270Z","shell.execute_reply":"2023-07-28T11:23:03.987113Z","shell.execute_reply.started":"2023-07-28T11:22:51.701427Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ÙˆÙØ§Ø«Ù’Ù†ÙÙŠÙ’Ù†Ù ÙˆÙØ³ÙØªÙÙŠÙ†Ù ÙÙÙŠ Ø§Ù„Ù’Ù…ÙØ¦ÙØ©Ù\n"]}],"source":["# Define the input text\n","inp=\"|Ø²Ù|ÙŠÙØ§Ù’|Ø¯Ù|ØªÙÙ†Ù’|ÙÙÙ„Ù’|Ù…Ù|Ø¨ÙÙŠÙ’|Ø¹ÙØ§Ù’|ØªÙ|ÙˆÙÙ„Ù’|Ø¡ÙØ±Ù’|Ø¨Ù|Ø§ÙØ­Ù’|Ù„ÙÙ„Ù’|Ø¹ÙØ§Ù’|Ù…ÙØ«Ù’|Ø«ÙØ§Ù’|Ù…Ù|Ù†Ù|Ø¹Ù|Ù„ÙÙ‰ØªÙ’|ØªÙ|ÙˆÙØ§Ù’|Ù„ÙÙŠÙ’.\"\n","t='|ÙÙÙŠÙ’|Ù…ÙÙ†Ù’|Ø·Ù|Ù‚Ù|ØªÙØ´Ù’|Ø´ÙØ±Ù’|Ù‚ÙÙ„Ù’|Ø¡ÙÙˆÙ’|Ø³ÙØ·Ù’|ÙˆÙ|ØªÙØ±Ù’|ÙƒÙ|ÙŠÙØ§Ù’|ÙˆÙ|Ø´Ù|Ù…Ù|Ø§ÙÙ„Ù’|Ø¡ÙÙÙ’|Ø±ÙÙŠÙ’|Ù‚Ù|ÙŠÙØ§Ù’.'\n","g='|ÙˆÙ|Ø§ÙØ«Ù’|Ù†ÙÙŠÙ’|Ù†Ù|ÙˆÙ|Ø³ÙØªÙ’|ØªÙÙŠÙ’|Ù†Ù|ÙÙÙ„Ù’|Ù…Ù|Ø¡ÙÙ‡Ù’.'\n","# Tokenize the input text\n","input_ids = tokenizer.encode(g, return_tensors=\"pt\",)\n","\n","# Generate the output\n","output_ids = model.generate(\n","    input_ids,\n","    max_length=100,\n","    early_stopping=True,\n","    pad_token_id=tokenizer.pad_token_id,\n","    bos_token_id=tokenizer.bos_token_id,\n","    eos_token_id=tokenizer.eos_token_id,\n",")\n","\n","# Decode the output\n","output_text = tokenizer.decode(output_ids[0][1:], skip_special_tokens=True)\n","print(output_text.split(\".\")[0])"]}],"metadata":{"colab":{"name":"Summarization","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
